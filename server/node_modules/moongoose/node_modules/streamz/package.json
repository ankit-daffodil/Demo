{
  "name": "streamz",
  "version": "1.5.3",
  "description": "A Swiss-army-knife of a stream",
  "keywords": [
    "asynchronous",
    "stream"
  ],
  "scripts": {
    "test": "mocha"
  },
  "author": {
    "name": "Ziggy Jonsson",
    "url": "http://github.com/zjonsson/"
  },
  "repository": {
    "type": "git",
    "url": "http://github.com/ZJONSSON/streamz"
  },
  "main": "streamz.js",
  "license": "MIT",
  "dependencies": {
    "bluebird": "~3.2.2"
  },
  "readme": "#### Streamz - generic all-purpose stream for an object pipeline.\n\nThe native stream.Transform does not provide concurrent operations out of the box or multiple incoming pipes going into a single transform.  Streamz is a lightweight wrapper around the Transform stream:\n\n* Executes custom functions (i.e. writes, transforms, filters, pushes) concurrently up to a user defined cap.\n* Tracks outstanding asynchronous functions by waiting for callbacks or resolved promises\n* Keeps count of incoming pipes as they are initiated and reduces count when they end\n* Issues 'end' only when all incoming pipes have ended\n* Issues 'finish' only when all incoming pipes have ended and any concurrent functions have finished\n* Provides downstream pipes in all instances.  If nothing is \"pushed\", the downstream pipe will only receive the end event (at the right time).\n* Passes errors down to the first listener in the chain\n* Provides an easy transition to final promise that is resolved on `finish` and rejected on `error`\n\nThe stream initiation is as follows (can be called with or without `new`):\n\n```js\nstreamz(fn,[options]);\n\n// alternative signature for specifying maximum concurrency:\nstreamz(concurrency,fn,[options])\n\n```\nThe user-supplied function (`fn`) is executed for each incoming object (either written directly with `.write` or piped from above).  The function must have either one or two arguments.  The first argument represents each incoming data packet and the second one is an optional callback.   The function can return nothing, a value or a promise.\n\nThe function can execute multiple manual pushes (`this.push(data)`) to pass any objects downstream.  If the function returns a value (`!= undefined` and not a promise), that value is automatically pushed.   If the function returns a promise that ultimately returns a non-undefined value, that final value is pushed too.  And finally if (optionally) a callback returns a value that gets pushed as well.  Basically any non-undefined returns through function results, callbacks or promise results get automatically pushed.  Therefore if you want to only manually push from inside the function make sure that any return values (or resolves) show up as `undefined`.\n\nWhen defining a custom function you can chose between a static function, a function with a callback and a function that returns a Promise.   The static function is considered immediately resolved upon execution, whereas the others are considered asynchronous. However, a custom function can also utilize a callback and a promise at the same time - in which case the callback signals when the stream is ready to receive next packet and the promise fulfillment signals when the processing is done.   This allows concurrency management linked to connection pools (i.e. fire cb when a pool issued an available connection) while the promise doesn't get resolved until the corresponding database call has completed.   Using this approach, a stream will not `finish` until outstanding promises have resolved - in addition to any callbacks.\n\nOptions are passed on to the parent Transform stream, however `objectMode` is explicitly set as `true`.  By default, the execution of user-supplied function is sequential (i.e. only one function runs at a time). This can be changed by specifying the maximum concurrent functions through a `concurrency` property in the options (defaults to 1).   Keep in mind that with concurrent cap above one, the order of the outputs might be different from the inputs.\n\nConcurrency can also be defined through the alternative function signature, where the maximum concurrency is the first argument, fn as the second and options as the third.\n\nIf you specify the option `keepAlive: true`, the `streamz` object will need an extra `.end()` to close.   This prevents accidental closing when piping multiple streams with uncertain timings (including periods of no open streams) into a `streamz` object.\n\nAs with vanilla node streams, a custom [`_flush()`](http://nodejs.org/api/stream.html#stream_transform_flush_callback) function can be defined to handle any remaining buffers after all written data has been consumed.  It is important however to call the '_flush' function of the `streamz` object prior to custom flushes.   Here is an example of how a custom buffer might be flushed:\n\n```js\nCustomstream.prototype._flush = function(cb) {\n  var self = this;\n  Streamz.prototype._flush.call(this,function() {\n    self.push(self.customBuffer);\n    setImmediate(cb);\n  });\n};\n```\n\nAny errors that come up in a streamz object are passed to the children if no custom error listener has been defined.  This allows errors to propagate down to the first error listener or to the rejection of a final promise (if the chain ends in `.promise()`)\n\nA chain that ends with `.promise()` returns a promise that collects any data passed down in an array and resolves when the stream is `finished` or is rejected if any uncaught error occured.   If no data is passed down to the end, the promise simply resolves to an empty array.\n",
  "readmeFilename": "README.md",
  "bugs": {
    "url": "https://github.com/ZJONSSON/streamz/issues"
  },
  "_id": "streamz@1.5.3",
  "dist": {
    "shasum": "594adc4e818750f5320ed9f706d8387e2ab99e30"
  },
  "_from": "streamz@^1.5.2",
  "_resolved": "https://registry.npmjs.org/streamz/-/streamz-1.5.3.tgz"
}
